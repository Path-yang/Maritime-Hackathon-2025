{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KzUwjMwpKm2",
        "outputId": "179a856e-6be7-4342-f24f-177cf30c717e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annotation Severity Types and Frequencies:\n",
            "annotation_severity\n",
            "Medium              6919\n",
            "Low                 6859\n",
            "High                4042\n",
            "Not a deficiency     150\n",
            "NaN                   21\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'psc_severity_train.csv'  # Replace with the correct file path\n",
        "train_data = pd.read_csv(file_path)\n",
        "\n",
        "# Count unique values and their frequencies in `annotation_severity`\n",
        "annotation_severity_counts = train_data['annotation_severity'].value_counts(dropna=False)\n",
        "\n",
        "print(\"Annotation Severity Types and Frequencies:\")\n",
        "print(annotation_severity_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76jSOSDUpOhS",
        "outputId": "e6b615c3-1933-4fbd-cd5d-05e90bc06cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VesselGroup Types and Frequencies:\n",
            "VesselGroup\n",
            "Dry Bulk         12830\n",
            "General Cargo     2007\n",
            "Container         1127\n",
            "Chemical          1107\n",
            "Oil                492\n",
            "Ro-Ro              220\n",
            "Liquefied Gas      205\n",
            "Miscellaneous        3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count unique values and their frequencies in `VesselGroup`\n",
        "vessel_group_counts = train_data['VesselGroup'].value_counts(dropna=False)\n",
        "\n",
        "print(\"VesselGroup Types and Frequencies:\")\n",
        "print(vessel_group_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nru4wyHpO3c",
        "outputId": "f1036564-dc3e-421e-a1a5-10443178dfc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Age Ranges and Frequencies:\n",
            "age_group\n",
            "11-15 years    8353\n",
            "6-10 years     3612\n",
            "16-20 years    3002\n",
            "0-5 years      1868\n",
            "21-30 years    1097\n",
            "31-40 years      44\n",
            "41-50 years      15\n",
            "50+ years         0\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Define age ranges\n",
        "age_bins = [0, 5, 10, 15, 20, 30, 40, 50, float('inf')]\n",
        "age_labels = ['0-5 years', '6-10 years', '11-15 years', '16-20 years', '21-30 years', '31-40 years', '41-50 years', '50+ years']\n",
        "\n",
        "# Classify ages into the defined ranges\n",
        "train_data['age_group'] = pd.cut(train_data['age'], bins=age_bins, labels=age_labels, right=True)\n",
        "\n",
        "# Count frequencies of each age group\n",
        "age_group_counts = train_data['age_group'].value_counts()\n",
        "\n",
        "print(\"Age Ranges and Frequencies:\")\n",
        "print(age_group_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "Ho6WcFwUVNlA",
        "outputId": "4f5f7e04-7aa3-47c4-9a68-8a79fbc22ab7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-ab403aa31b09>:106: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(resolve_ties)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted severity has been saved to 'resolved_predicted_severity.csv'.\n",
            "   PscInspectionId deficiency_code  annotation_id username  \\\n",
            "0          1702496           01104       42180251   mihail   \n",
            "1          1702496           01104       42532116     marc   \n",
            "2          1702496           01104       42631723     raul   \n",
            "3          1795901           10135       42190695   mihail   \n",
            "4          1795901           10135       42851742     raul   \n",
            "5          1795901           10135       43136020     marc   \n",
            "6          1667488           10135       42224469   mihail   \n",
            "7          1667488           10135       43206905     marc   \n",
            "8          1667488           10135       43217322     raul   \n",
            "9          1733202           10135       42224484   mihail   \n",
            "\n",
            "  annotation_severity                                           def_text  \\\n",
            "0                 Low  PscInspectionId: 1702496\\n\\nDeficiency/Finding...   \n",
            "1                High  PscInspectionId: 1702496\\n\\nDeficiency/Finding...   \n",
            "2                High  PscInspectionId: 1702496\\n\\nDeficiency/Finding...   \n",
            "3              Medium  PscInspectionId: 1795901\\n\\nDeficiency/Finding...   \n",
            "4              Medium  PscInspectionId: 1795901\\n\\nDeficiency/Finding...   \n",
            "5                High  PscInspectionId: 1795901\\n\\nDeficiency/Finding...   \n",
            "6              Medium  PscInspectionId: 1667488\\n\\nDeficiency/Finding...   \n",
            "7                High  PscInspectionId: 1667488\\n\\nDeficiency/Finding...   \n",
            "8              Medium  PscInspectionId: 1667488\\n\\nDeficiency/Finding...   \n",
            "9              Medium  PscInspectionId: 1733202\\n\\nDeficiency/Finding...   \n",
            "\n",
            "  InspectionDate  VesselId  PscAuthorityId   PortId VesselGroup        age  \\\n",
            "0     2023-04-24    141884               7     2028    Chemical  20.813142   \n",
            "1     2023-04-24    141884               7     2028    Chemical  20.813142   \n",
            "2     2023-04-24    141884               7     2028    Chemical  20.813142   \n",
            "3     2024-03-11    292540               9  1000736    Dry Bulk  11.523614   \n",
            "4     2024-03-11    292540               9  1000736    Dry Bulk  11.523614   \n",
            "5     2024-03-11    292540               9  1000736    Dry Bulk  11.523614   \n",
            "6     2022-12-13    303546               1     1098    Dry Bulk   7.786448   \n",
            "7     2022-12-13    303546               1     1098    Dry Bulk   7.786448   \n",
            "8     2022-12-13    303546               1     1098    Dry Bulk   7.786448   \n",
            "9     2023-08-04    286265               9      936    Dry Bulk  12.673511   \n",
            "\n",
            "  predicted_severity  \n",
            "0               High  \n",
            "1               High  \n",
            "2               High  \n",
            "3               High  \n",
            "4               High  \n",
            "5               High  \n",
            "6             Medium  \n",
            "7             Medium  \n",
            "8             Medium  \n",
            "9               High  \n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41c7b209-dd10-40f4-837a-a3670eac6607\", \"resolved_predicted_severity.csv\", 23138093)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "file_path = 'psc_severity_train.csv'  # Replace with the correct file path\n",
        "train_data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Preprocess the dataset\n",
        "# Ensure deficiency codes are 5 digits with leading zeros if necessary\n",
        "train_data['deficiency_code'] = train_data['deficiency_code'].apply(lambda x: str(int(x)).zfill(5))\n",
        "\n",
        "# Drop rows with null/blank values in annotation_severity\n",
        "train_data = train_data.dropna(subset=['annotation_severity'])\n",
        "\n",
        "# Step 3: Extract TF-IDF keywords from def_text\n",
        "vectorizer = TfidfVectorizer(max_features=50, stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(train_data['def_text'])\n",
        "keywords = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Analyze relationships between keywords and annotation_severity\n",
        "high_indicators, low_indicators, medium_indicators, nad_indicators = [], [], [], []\n",
        "\n",
        "for keyword in keywords:\n",
        "    keyword_presence = train_data['def_text'].str.contains(keyword, case=False, na=False)\n",
        "    severity_distribution = train_data.loc[keyword_presence, 'annotation_severity'].value_counts(normalize=True)\n",
        "\n",
        "    if 'High' in severity_distribution and severity_distribution['High'] > 0.7:\n",
        "        high_indicators.append(keyword)\n",
        "    elif 'Low' in severity_distribution and severity_distribution['Low'] > 0.7:\n",
        "        low_indicators.append(keyword)\n",
        "    elif 'Medium' in severity_distribution and severity_distribution['Medium'] > 0.7:\n",
        "        medium_indicators.append(keyword)\n",
        "    elif 'Not a deficiency' in severity_distribution and severity_distribution['Not a deficiency'] > 0.7:\n",
        "        nad_indicators.append(keyword)\n",
        "\n",
        "# Step 4: Define VesselGroup and Age Points\n",
        "vessel_points = {\n",
        "    'Tanker': 10,\n",
        "    'Gas Carrier': 9,\n",
        "    'Container': 8,\n",
        "    'Dry Bulk': 7,\n",
        "    'Passenger': 6,\n",
        "    'Fishing': 4,\n",
        "    'General Cargo': 5,\n",
        "    'Others': 3\n",
        "}\n",
        "\n",
        "def calculate_age_points(age):\n",
        "    if age <= 5:\n",
        "        return 2\n",
        "    elif 5 < age <= 10:\n",
        "        return 4\n",
        "    elif 10 < age <= 15:\n",
        "        return 6\n",
        "    elif 15 < age <= 20:\n",
        "        return 8\n",
        "    elif 20 < age <= 30:\n",
        "        return 10\n",
        "    elif 30 < age <= 40:\n",
        "        return 8\n",
        "    elif 40 < age <= 50:\n",
        "        return 5\n",
        "    else:\n",
        "        return 2  # For ages beyond 50, assign lower points due to reduced activity.\n",
        "\n",
        "# Step 5: Tie-Breaking Logic with Weighted Point System\n",
        "def resolve_ties(group):\n",
        "    severities = group['annotation_severity'].tolist()\n",
        "    if len(set(severities)) == 1:  # If all annotations are the same, return directly\n",
        "        return severities[0]\n",
        "\n",
        "    # Count votes for each severity\n",
        "    severity_votes = pd.Series(severities).value_counts()\n",
        "    max_votes = severity_votes.max()\n",
        "    plurality_severities = severity_votes[severity_votes == max_votes].index.tolist()\n",
        "\n",
        "    if len(plurality_severities) == 1:\n",
        "        return plurality_severities[0]  # Plurality wins\n",
        "\n",
        "    # If still tied, apply the point-based system\n",
        "    def_text = group['def_text'].iloc[0]\n",
        "    vessel_group = group['VesselGroup'].iloc[0]\n",
        "    age = group['age'].iloc[0]\n",
        "\n",
        "    scores = {'High': 0, 'Medium': 0, 'Low': 0, 'Not a deficiency': 0}\n",
        "\n",
        "    # Add points from def_text\n",
        "    scores['High'] += sum(5 for keyword in high_indicators if keyword in def_text)\n",
        "    scores['Medium'] += sum(3 for keyword in medium_indicators if keyword in def_text)\n",
        "    scores['Low'] += sum(1 for keyword in low_indicators if keyword in def_text)\n",
        "    scores['Not a deficiency'] += sum(0 for keyword in nad_indicators if keyword in def_text)\n",
        "\n",
        "    # Add points from VesselGroup\n",
        "    if vessel_group in vessel_points:\n",
        "        scores['High'] += vessel_points[vessel_group]\n",
        "\n",
        "    # Add points from age\n",
        "    scores['High'] += calculate_age_points(age)\n",
        "\n",
        "    # Return the severity with the highest score\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "# Step 6: Apply Consensus Logic\n",
        "consensus = (\n",
        "    train_data.groupby(['PscInspectionId', 'deficiency_code'])\n",
        "    .apply(resolve_ties)\n",
        "    .reset_index(name='predicted_severity')\n",
        ")\n",
        "\n",
        "# Step 7: Merge the predicted severity back to the original dataset\n",
        "train_data = train_data.merge(consensus, on=['PscInspectionId', 'deficiency_code'])\n",
        "\n",
        "# Step 8: Save the resulting DataFrame to a CSV file\n",
        "output_file = 'resolved_predicted_severity.csv'\n",
        "train_data.to_csv(output_file, index=False)\n",
        "\n",
        "# Step 9: Display a Preview of the Resulting Dataset\n",
        "print(f\"Predicted severity has been saved to '{output_file}'.\")\n",
        "print(train_data.head(10))\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Step 10: Download the resolved CSV file\n",
        "files.download('resolved_predicted_severity.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
